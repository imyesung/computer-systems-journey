## Exercise 01

최대 힙에서는 가장 큰 원소가 항상 루트에 있다. 즉, 루트의 깊이가 가장 얕다. 임의의 최대 힙에서 더 얕은 곳에 있는 원소가 더 깊은 곳에 있는 원소보다 더 작은 값을 가질 수 있는가?

### Answer 
'_최대 힙에서는 가장 큰 원소가 항상 같은 루트에 있다._'와 '_모든 얕은 노드가 모든 깊은 노드보다 크다._'는 것은 별개의 명제이다. Root node가 최댓값을 가지고 있어도 더 얕은 노드가 더 깊은 노드 보다 작은 값을 가지는 **최대 힙**이 존재할 수 있다.

모든 부모 노드의 값은 직속 자식 노드보다 값이 크거나 같아야 함이 heap이 '값'에 둔 유일한 규칙이다. 이 규칙이 모든 노드에 재귀적으로 적용되기 때문에 Root node는 모든 Child node 보다 크거나 같음이 보장되어, Root node가 해당 트리 전체의 최댓값이 된다.

$$key(Parent) >= key(Child)$$

이 규칙은 **local**이라는 점을 기억하자. 위 규칙은 수직적이고 지역적인 '부모-자식' 관계만 제약하고, 형제 노드나 사촌(서로 다른 가지에 있는 노드) 사이와 같이 전역적인 대소 관계에는 아무 것도 강제하지 않는다.

그러므로 부모-자식 관계가 아닌 원소들은 힙 규칙을 어기지 않는 한 더 얕은 곳의 원소가 더 깊은 곳에 있는 원소보다 작은 값을 가질 수 있다.

**∴**  이 명제는 참이다.

## Exercise 02
최대 힙 `A[0…n-1]`에서 `A[0]`는 항상 가장 큰 값을 갖고 있다. 반대로 마지막 원소인 `A[n-1]`는 항상 가장 작은 값을 갖는가?

### Answer 
그렇지 않다.
<br> 마지막 원소인 `A[n-1]`은 가장 깊은 노드 중 오른쪽에 위치한 **leaf node**로, 자신의 부모 노드보다는 작은 값이지만 이것이 트리 전체의 최솟값이라는 보장은 없다.

## Exercise 03
임의의 배열 `A[0…n-1]`을 힙으로 만드는 `buildHeap()` 알고리즘에서, 총 `n`개의 원소 중 루트의 자격으로 스며내리기를 할지 알아보지 않고 그냥 넘어가는 원소(힙의 노드) 수는 정확하게 몇 개인가?

### Answer
`buildHeap()`은 **배열의 모든 원소를 힙 특성에 맞게 재배치**한다. 스며내리기는 특정 노드를 Root로 하여, 그 자식 노드들과 값을 비교하고 교환하는 과정이다.

1. 스며내리기를 하려면 비교할 Child node가 최소 1개는 있어야 한다.
2. 하지만 트리 가장 깊은 곳에 있는 Leaf node는 자식 노드가 아예 없다.
3. 따라서 Leaf node에는 스며내리기를 수행할 필요가 없다. 이 노드들이 **그냥 넘어가는 원소들**이다.

03의 질문을 다시 정의해보면, "_총 `n`개의 노드 중 Leaf node의 개수가 몇 개인가?_"와 같다.
- 총 노드 수: $n$
- 스며내리기 수행 노드 (Parent node) 개수: $\lfloor\frac{n}{2}\rfloor$
- 스며내리기 생략 노드 (Leaf node) 개수: $n - \lfloor\frac{n}{2}\rfloor = \lceil\frac{n}{2}\rceil$ 

    **∴  $\lceil\frac{n}{2}\rceil$**


## Exercise 04
배열 `A[0…n-1]`을 대상으로 하는 스며내리기 알고리즘에서 최악의 경우에 해당하는 시간과 최선의 경우에 해당하는 시간은 어떻게 되는가? $\Theta-$표기로 나타내시오.

### Answer

스며내리기 알고리즘이 '언제 일을 가장 적게 하고, 언제 가장 많이하는지' 생각해보자.

```
percolateDown(k):
    child <- 2k+1       ◀ left child
    right <- 2k+2       ◀ right child
    if (child <= n-1)
        if (right <= n-1 and A[child] < A[right])
            child <- right
        ◀ child: A[2k+1]와 A[2k+2] 중 큰 원소의 인덱스
        if (A[k] < A[child])
            A[k] <-> A[child]   ◀ 맞바꾸기
            percolateDown(child)
```

최선의 경우는 $\Theta(1)$으로, 힙의 전체 크기($n$)와 관계 없이 항상 일정한 시간이 걸린다.
1. `percolateDown(k)`가 시작되면
2. Child node 두 개 중에 **더 큰 값**을 가진 자식의 index를 찾는다.
3. `if (A[k] < A[child])`를 수행한다.
4. 최선의 경우, 이미 `A[k]` >= `A[child]`이 충족되므로, 이 조건은 **false**가 된다.
5. 따라서, `if`문 안의 맞바꾸기(`A[k] <-> A[child]`)와 재귀 호출이 실행되지 않고 함수가 즉시 종료된다.

최악의 경우는 $\Theta(\log n)$으로, **작업 시간이 힙의 높이에 비례한다**. 힙은 데이터($n$)가 2배로 늘어나도 높이는 1씩 증가하는 효율적인 구조로 되어있다.

1. `percolateDown(k)`가 힙의 맨 위(Root, $k=0$)에서 시작된다.
2. Child node 두 개 중에 더 큰 값을 가진 자식의 index를 찾는다.
3. `if (A[k] < A[child])`를 수행한다.
4. 최악의 경우, `A[k]`가 `A[child]`보다 **작아서**, 이 조건은 항상 **true**이다.
    - _e.g., `deleteMax` 직후 맨 마지막의 작은 값이 Root node로 올라온 경우_
5. `if`문 안의 맞바꾸기(`A[k] <-> A[child]`)와 재귀 호출(`perlocateDown(child)`)이 실행된다.
6. 이 과정을 한 레벨 아래(child 위치)에서 또다시 반복하고, 힙의 맨 아래(leaf node)에 도달할 때까지 매 레벨마다 계속 실행한다.
7. 이처럼 최악의 경우 **맞바꾸기 + 재귀호출**은 힙의 root에서 leaf까지 이어진다. 이 전체 경로는 힙의 높이($\log n$에 비례)와 같으므로 $\Theta(\log n)$이다.

## Exercise 05
힙인 상태에서 원소 삭제는 루트 노드만 대상으로 한다. 다른 경우는 존재하지 않는다. 테스트 목적으로 힙의 맨 마지막 원소를 삭제하는 작업을 요구한다면 간단한 일인가?

### Answer
힙이 만족해야하는 두 가지 조건이 깨지지 않으므로 간단하다.
1. 힙의 맨 마지막 원소($A[n-1]$)는 완전 이진 트리에서 '가장 깊은 레벨의 가장 오른쪽 노드'이다. 이 노드를 제거해도 완전 이진 트리의 구조는 유지된다. 

    _**cf.**_ 오히려 힙의 Root node($A[0]$)를 삭제하는 경우가 가장 복잡한데, Root를 삭제할 경우 구조가 깨지고, $A[n-1]$을 $A[0]$으로 옮겨와 구조를 보존해야 하기 때문에 복잡하다.  

2. 힙의 값이 가진 특성으로 '맨 마지막 원소'는 항상 **Leaf node**이다. Leaf node는 자식이 없으므로 이 노드가 사라져도, 다른 노드 간의 부모-자식 대소 관계(heap property)가 깨지지 않는다.

**∴** 간단하다. 맨 마지막 원소를 삭제하는 작업은 '스며오르기'나 '스며내리기' 같이 힙을 수선하는 작업이 필요하지 않으므로 $\Theta(1)$ (상수 시간)에 완료 된다.

## Exercise 06
어떤 학생이 다음과 같은 질문을 했다.
"`buildHeap()` 알고리즘에서는 아래쪽에서부터 시작해서 스며내리기를 반복하는데, 만약 반대 방향으로 하면 어떤가요? (즉, 위쪽에서부터 시작해서 스며오르기를 반복)" 이렇게 해도 힙이 만들어진다. 이 방법은 본문에 제시한 방법에 비해 더 효율적인가? 점근적 시간으로 말하시오.

```
buildHeap():  ◀ 배열 A[0...n-1]을 힙으로 만든다
for i ← (n-2)/2 downto 0
    percolateDown(i)
```

### Answer
`buildHeap()`을 구성하는 두 가지 방식의 **점근적 효율성**을 비교해보자.

- 기존 방식: 아래에서 위로 스며내리기(`percolateDown`) 사용 표준
- 학생 방식: 위에서 아래로 스며오르기(`perlocateUp`) 반복하는 방식

학생이 제안한 '위에서 아래로 스며오르기' 방식은 기존의 '아래에서 위로 스며내리기' 방식보다 점근적으로 비효율적이다.

학생의 '스며오르기(`percolateUp`)' 방식은 $\Theta(n)$ 번의 삽입을 한다. 이 방식에서는 전체 노드의 절반 정도를 차지하는 leaf node($n/2$ 개)가 삽입될 때, 긴 거리($\Theta(\log n)$)를 반드시 이동해야 한다. 따라서 총합은 $\sum_{i=1}^{n} \Theta(\log i)$이 되어 $\Theta(n \log n)$의 점근적 효율성을 가진다.

반면, 기존의 '스며내리기(`buildHeap`)' 방식은 완전 이진 트리의 특성을 가진 힙이 바닥이 극도로 무거운(bottom-heavy) 구조임을 활용한다.

`buildHeap()`의 `for` 루프가 처리하는 노드의 대다수(약 $n/4$ 개)는 바닥 바로 위에 있어, "바닥까지의 높이($h$)"가 1칸으로 $O(1)$의 점근적 효율성을 가진다. 가장 긴 거리 이동을 해야하는 $O(\log n)$의 비용이 드는 노드는 Root node 단 하나뿐이다. 따라서 기존 방식 합계는 $\Theta(n)$으로 수렴한다.

$$T(n) \approx \sum_{h=1}^{\log n} (\frac{n}{2^{h+1}}) \times O(h)$$

따라서 '많은 노드'가 짧은 거리 $O(1)$만 이동하는 기존 방식에 비하여, 학생의 방식은 비효율적이다.

## Exercise 07
$n$ 개의 원소로 이루어진 최대 힙에서 임의의 원소 값이 증가했을 때 $O(\log n)$ 시간에 이를 반영해서 힙을 수선할 수 있다. 어떻게 하면 되는지 그 과정을 기술하시오.

### Answer 
Max heap에서 임의의 원소 값이 증가했을 때, 힙 속성을 복구하기 위해 `percolate-up(스며오르기)` 방법으로 힙을 수선한다.
최대 힙은 "부모 노드의 값 >= 자식 노드의 값" 속성을 가지고 있다. 이에 어떤 노드의 값이 증가할 경우, 그 노드는 자신의 자식 노드들 보다는 여전히 크거나 같을 것이다. 따라서 그 노드를 root로 하는 subtree는 여전히 최대 힙 상태를 유지한다.

하지만 값이 증가한 노드가 자신의 부모 노드보다 값이 커질 수 있으며, 이는 힙 속성을 위반한다. 따라서 문제는 현재 노드와 그 '위쪽' 조상 노드들 관계의 문제이다. 이를 수선하는 프로세스는 아래와 같다.

1. 값이 증가한 노드의 위치(index $i$)에서 시작
2. $i$를 $i$의 parent node(index $\lfloor (i-1)/2 \rfloor$)와 비교
3. 만약 $i$가 parent node보다 크다면, 두 노드의 위치를 **swap**
4. index $i$는 방금 이동한 parent node의 위치를 가리키도록 갱신
5. 새로 갱신된 $i$가 자신의 (새로운) 부모보다 작거나 같아질 때까지,혹은 root node에 도달할 때까지 2-4번을 반복

예제의 점근적 시간 복잡도는 $O(\log n)$인데, 최악의 상황(e.g., leaf node의 값이 증가하여 root까지 계속 올라가는 경우)에도 그 연산 횟수가 $\log n$에 비례하는 수준을 넘지 않는다. 최선의 경우는 $\Omega(1)$로, 값이 증가한 노드가 여전히 자신의 parent node보다 값이 작거나 같아서, 단 한 번의 swap도 필요 없는 때이다. 이때는 한 번의 비교만으로 $O(1)$의 상수 시간만에 연산이 즉시 종료된다.

이 연산의 시간 복잡도는 $O(\log n)$, $\Omega(1)$으로, 최선과 최악의 경우에 대한 점근적 성장률이 다르다. 따라서 해당 알고리즘의 성능을 단일 $\Theta$ 표기법으로는 나타낼 수 없다.


---

## References

- https://xlinux.nist.gov/dads/HTML/heap.html
- https://xlinux.nist.gov/dads/HTML/priorityque.html